<launch>
	# roobma_robin bringup procedure
	<include file="$(find roomba_robin_bringup)/launch/minimal.launch"/>
	
	# navigation
	<include file="$(find turtlebot_navigation)/launch/amcl_demo.launch">
	    <arg name="map_file"  value="/home/turtlebot/fullMap.yaml"/>
	</include>
	
	# transform from map to threshold position of persons to be approached and asked about a tour
	<node pkg="tf" type="static_transform_publisher" name="person_threshold_broadcaster" args="3 0 0 0 0 0 map person_threshold 1000" />
	
	# load parameters (such as coordinates of goals, etc.)
	<rosparam file="$(find wheeled_robin_guided_tour)/launch/parameters.yaml" command="load" ns="goals" />
	
	# guided tour state machine
	<node pkg="wheeled_robin_guided_tour" name="state_machine" type="state_machine">
		
		# range (from base) to trigger area (triggering radius)
		<param name="base_range" value="1.0" type="double" />
		
		# frame of identified person/group ("/dominant_person" or "/group")
		<param name="person_frame" value="/dominant_person" type="string" />
		
		# name of frame of person position threshold
		<param name="person_threshold_frame" value="/person_threshold_frame" type="string" />
		
		# validity duration for button events
		<param name="button_duration" value="20.0" type="double" />
		
		# basename for goal parameters (e.g. "goal_1","goal_2", ... where "goal_" is basename)
		<param name="goal_basename" value="goal_" type="string" />
		
		# absolute path to parent video folder
		<param name="video_path" value="/home/turtlebot/rob_video" type="string" />
		
	</node>
	
	# connection to Arduino for hardware user interface
	<node pkg="rosserial_python" type="serial_node.py" args="/dev/ttyACM0" name="rosserial"/>
	
	# person tracking node
	<node name="openni_tracker" pkg="openni_tracker" type="openni_tracker" args="-d $(find openni_tracker)/openni_tracker.xml">
		<param name = "camera_frame_id" value = "/camera_link" />
	</node>
	
	# person detection node
	<node pkg="robin_people_detection" type="robin_people_detection" name="robin_people_detection" output="screen" />
	
	# speech synthesis
	<!--<include file="$(find speech_database)/launch/speech.launch"/>-->
	
	# video player
	<arg name="cam_name" value="videoStreamer" />
	<node pkg="video_player" type="video_player_node" name="$(arg cam_name)">
	        <param name="mode" value="mode_II" />
	        <param name="camera_name" value="$(arg cam_name)" />
	        <remap from="camera/image_raw" to="camera/rgb/image_color/compressed_throttle" />
       </node>
</launch>
